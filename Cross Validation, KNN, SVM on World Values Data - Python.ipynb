{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the nexessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import shuffle\n",
    "import statistics\n",
    "from sklearn.svm import SVC\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore and prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load the data. How many responses and variables do we have?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "wvs = pd.read_csv('wvs.csv.bz2', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V2</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>...</th>\n",
       "      <th>MN_228S8</th>\n",
       "      <th>MN_229A</th>\n",
       "      <th>MN_230A</th>\n",
       "      <th>MN_233A</th>\n",
       "      <th>MN_237B1</th>\n",
       "      <th>MN_249A1</th>\n",
       "      <th>MN_249A3</th>\n",
       "      <th>I_RELIGBEL</th>\n",
       "      <th>I_NORM1</th>\n",
       "      <th>I_VOICE1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 328 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V2  V4  V5  V6  V7  V8  V9  V10  V11  V12  ...  MN_228S8  MN_229A  MN_230A  \\\n",
       "0  12   1   1   1  -2   1   1    2    1    1  ...         3       -3       -3   \n",
       "1  12   1   2   3   4   2   2    2    2    2  ...         3       -3       -3   \n",
       "2  12   1   3   2   4   2   1    2    2    2  ...         4        1        1   \n",
       "3  12   1   1   3   4   3   1    2    1    2  ...         2        2        1   \n",
       "4  12   1   1   1   2   1   1    1    3    2  ...         2        2        1   \n",
       "\n",
       "   MN_233A  MN_237B1  MN_249A1  MN_249A3  I_RELIGBEL  I_NORM1  I_VOICE1  \n",
       "0       -3        -3         1         1         0.0      1.0      0.00  \n",
       "1       -3        -3         2        -1         0.0      1.0      0.66  \n",
       "2        2        -3         1         1         0.0      1.0      0.33  \n",
       "3        2        -3         1         2         0.0      1.0      0.00  \n",
       "4        2        -3         1         2         0.0      1.0      0.66  \n",
       "\n",
       "[5 rows x 328 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validating the data\n",
    "wvs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90350, 328)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the number of rows and columns\n",
    "wvs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are totally 90350 rows(responses) in the data and 328 columns(variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q: Create a summary table over all responses for V204:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    90350.000000\n",
       "mean         2.946386\n",
       "std          2.964040\n",
       "min         -5.000000\n",
       "25%          1.000000\n",
       "50%          2.000000\n",
       "75%          5.000000\n",
       "max         10.000000\n",
       "Name: V204, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a summary for column 'V204'\n",
    "wvs['V204'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q: Now remove missings.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85742, 328)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking number of positive answers\n",
    "wvs[wvs['V204'] > 0].shape\n",
    "#85742 positive responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are totally 85742 rows consisting of positive responses to abortion.\n",
    "Out of 90350, approximately 94% have positive responses towards abortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the missings\n",
    "wvs2 = wvs[(wvs['V204']>0) & (wvs['V2']>0)]\n",
    "wvs2 = wvs2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79267, 328)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the number of rows after removing the missings\n",
    "wvs2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final number of observations are 79267"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q: In order to simplify the analysis below, create a new binary variable abortion__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a binary column known as abortion\n",
    "wvs2['abortion'] = np.where(wvs2['V204']>3, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirms the binary responses\n",
    "wvs2['abortion'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q: Compute (pearson) correlation table between abortion and all other variables in the data.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abortion    1.000000\n",
       "V204        0.881048\n",
       "V205        0.548653\n",
       "V203        0.485419\n",
       "V206        0.446394\n",
       "Name: abortion, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computing the correlation table in descending order\n",
    "wvs2.corr()['abortion'].sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V138   -0.142894\n",
       "V255   -0.149844\n",
       "V223   -0.165924\n",
       "V252   -0.191483\n",
       "V152   -0.315280\n",
       "Name: abortion, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvs2.corr()['abortion'].sort_values(ascending=False).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q: convert country code V2 into dummies.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming V2 to country\n",
    "wvs2 = wvs2.rename(columns = {'V2': 'country'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 12,  32,  51,  36,  31,  48, 112,  76, 170, 196, 152, 156, 218,\n",
       "       233, 268, 276, 288, 344, 356, 368, 392, 400, 398, 417, 422, 434,\n",
       "       458, 484, 504, 528, 554, 566, 586, 275, 604, 608, 616, 634, 642,\n",
       "       643, 646, 702, 705, 410, 710, 724, 752, 158, 764, 780, 788, 792,\n",
       "       804, 840, 858, 860, 887, 716], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the validity of the change\n",
    "wvs2.country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting country to dummy variables\n",
    "wvs_dum = pd.get_dummies(wvs2, columns = ['country'])\n",
    "wvs_dum = wvs_dum.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13',\n",
       "       ...\n",
       "       'country_752', 'country_764', 'country_780', 'country_788',\n",
       "       'country_792', 'country_804', 'country_840', 'country_858',\n",
       "       'country_860', 'country_887'],\n",
       "      dtype='object', length=386)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking column names\n",
    "wvs_dum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79267, 386)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking how many extra columns we got\n",
    "wvs_dum.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new dataset after creating the dummy columns now contains 79267 rows and 386 columns.\n",
    "There are totally __58__ new dummy columns for country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function for K-fold CV\n",
    "def kfold2(k, model, X, y):\n",
    "    #Creating lists to keep track of the stats of each k\n",
    "    fscore, accuracy, precision, recall = [], [], [], []\n",
    "    #Making data\n",
    "    data = pd.concat([X,y], axis = 1)\n",
    "    #Shuffling data\n",
    "    data = shuffle(data)\n",
    "    #Creating folds\n",
    "    folds = np.array_split(data, k)\n",
    "    for i in range(k):\n",
    "        #Selecting necessary indexes\n",
    "        train_data = folds.copy()\n",
    "        test_data = folds[i]\n",
    "        del train_data[i]\n",
    "        train_data = pd.concat(train_data, sort=False)\n",
    "        #Making response and predictor variable\n",
    "        X_test = test_data[y.columns]\n",
    "        X_train = train_data[y.columns]\n",
    "        y_test = test_data[X.columns]\n",
    "        y_train = train_data[X.columns]\n",
    "        #Fitting the model\n",
    "        m = model.fit(y_train, X_train.values.ravel())\n",
    "        #Predicting the validation set\n",
    "        pred = m.predict(y_test)\n",
    "        accuracy.append(accuracy_score(pred, X_test))\n",
    "        fscore.append(f1_score(pred, X_test))\n",
    "        precision.append(precision_score(pred, X_test))\n",
    "        recall.append(recall_score(pred, X_test))\n",
    "    return([statistics.mean(accuracy), statistics.mean(fscore), statistics.mean(precision), statistics.mean(recall)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell I have made the necessary function to take the number of folds, the unfitted model, X and y and generate the mean statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking a sample of the data since my computer can't run the whole set\n",
    "wvs_dum_sample = wvs_dum.sample(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of the result: 0.7726999999999999\n",
      "Mean fscore of the result: 0.6831297018567125\n",
      "Mean precision of the result: 0.6787182847703916\n",
      "Mean recall of the result: 0.687970227738423\n"
     ]
    }
   ],
   "source": [
    "#Calling the KNN function with one neighbor and k=5\n",
    "X = pd.DataFrame(wvs_dum_sample.loc[:, wvs_dum.columns != 'abortion'])\n",
    "y = pd.DataFrame(wvs_dum_sample.abortion)\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "res = kfold2(5, knn, X, y)\n",
    "#Printing out the results\n",
    "print('Mean accuracy of the result:', res[0])\n",
    "print('Mean fscore of the result:', res[1])\n",
    "print('Mean precision of the result:', res[2])\n",
    "print('Mean recall of the result:', res[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_dum_sample = wvs_dum.sample(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of the result: 0.7656666666666666\n",
      "Mean fscore of the result: 0.6792828917568031\n",
      "Mean precision of the result: 0.6765256136319355\n",
      "Mean recall of the result: 0.6835062960510286\n"
     ]
    }
   ],
   "source": [
    "#Calling the KNN function with one neighbor and k=10\n",
    "X = pd.DataFrame(wvs_dum_sample.loc[:, wvs_dum.columns != 'abortion'])\n",
    "y = pd.DataFrame(wvs_dum_sample.abortion)\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "res = kfold2(10, knn, X, y)\n",
    "res\n",
    "print('Mean accuracy of the result:', res[0])\n",
    "print('Mean fscore of the result:', res[1])\n",
    "print('Mean precision of the result:', res[2])\n",
    "print('Mean recall of the result:', res[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the above question, I have ran the KNN twice once with 5 folds and once with 10 folds. The accuracy hasn't changed much with changing the number of folds.\n",
    "\n",
    "The accuracy for k=5 is 77% and k=10 is 76.5%\n",
    "\n",
    "There is no significant difference in the accuracy after changing the k value for the same data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacky fix for removing warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\", lineno=433)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of the result: 1.0\n",
      "Mean fscore of the result: 1.0\n",
      "Mean precision of the result: 1.0\n",
      "Mean recall of the result: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Making a logistic regression model and sending it to the function\n",
    "X = pd.DataFrame(wvs_dum.loc[:, wvs_dum.columns != 'abortion'])\n",
    "y = pd.DataFrame(wvs_dum.abortion)\n",
    "lmodel = LogisticRegression()\n",
    "res = kfold2(10, lmodel, X, y)\n",
    "print('Mean accuracy of the result:', res[0])\n",
    "print('Mean fscore of the result:', res[1])\n",
    "print('Mean precision of the result:', res[2])\n",
    "print('Mean recall of the result:', res[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, the accuracy, f-score, presicion and recall for the Logistic regression model is 1.0. The Logistic Regression model is run on the whole data set not a sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacky fix to remove warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\", lineno=196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of the result: 1.0\n",
      "Mean fscore of the result: 1.0\n",
      "Mean precision of the result: 1.0\n",
      "Mean recall of the result: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Running the SVM classifier with linear kernel.\n",
    "wvs_dum_sample = wvs_dum.sample(n=6000)\n",
    "X = pd.DataFrame(wvs_dum_sample.loc[:, wvs_dum_sample.columns != 'abortion'])\n",
    "y = pd.DataFrame(wvs_dum_sample.abortion)\n",
    "svclassifier = SVC(kernel='linear')\n",
    "res = kfold2(10, svclassifier, X, y)\n",
    "print('Mean accuracy of the result:', res[0])\n",
    "print('Mean fscore of the result:', res[1])\n",
    "print('Mean precision of the result:', res[2])\n",
    "print('Mean recall of the result:', res[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for this model is 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of the result: 0.9881666666666666\n",
      "Mean fscore of the result: 0.9834218162146652\n",
      "Mean precision of the result: 0.9785953289522696\n",
      "Mean recall of the result: 0.9883513068699523\n"
     ]
    }
   ],
   "source": [
    "#Running the SVM classifier with polynomial kernel with 1 degree\n",
    "svclassifier = SVC(kernel='poly', degree=1)\n",
    "res = kfold2(10, svclassifier, X, y)\n",
    "print('Mean accuracy of the result:', res[0])\n",
    "print('Mean fscore of the result:', res[1])\n",
    "print('Mean precision of the result:', res[2])\n",
    "print('Mean recall of the result:', res[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of the result: 0.9585\n",
      "Mean fscore of the result: 0.9416368806586395\n",
      "Mean precision of the result: 0.9293182984692685\n",
      "Mean recall of the result: 0.9544337904221653\n"
     ]
    }
   ],
   "source": [
    "#Running the SVM classifier with polynomial kernel with 8 degrees\n",
    "svclassifier = SVC(kernel='poly', degree=8)\n",
    "res = kfold2(10, svclassifier, X, y)\n",
    "print('Mean accuracy of the result:', res[0])\n",
    "print('Mean fscore of the result:', res[1])\n",
    "print('Mean precision of the result:', res[2])\n",
    "print('Mean recall of the result:', res[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, the SVC classifier with degree 8 reduced the precision and recall from the linear model.\n",
    "\n",
    "While the linear model gave the mean statistics as 1, the polynomial model gave 98% and 95% with degree=1 and degree=8 respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.4 Compare the models__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Finally, compare the models. Which ones performed the best in terms of accuracy? Which ones in terms of F-score? Did you encounter other kind of issues with certain models? Which models were fast and which ones slow?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic Regression model gave the best accuracy and F-score. It was 1.0 for all the statistics mean. The model performed the best for LR. \n",
    "No particular issues were encountered while running the models. \n",
    "KNN and SVM were relatively slower as compared to LR. I could only run a sample of the data through KNN. My system froze when I tried running the entire data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. If you have to repeat the exercise with a single model (and you have, see below), which one will you pick?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For repeating the execise, I would pick two models which are the LR model and the SVM model.\n",
    "\n",
    "LR model because it gave the best accuracy and SVM model because it gave comparable results on different kernels. Realistically, to compare the effect of a variable, I would test it using both the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How large a role does country play?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running on LR model first. It gave the best accuracy and f-score(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of the result: 1.0\n",
      "Mean fscore of the result: 1.0\n",
      "Mean precision of the result: 1.0\n",
      "Mean recall of the result: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Making a logistic regression model and sending it to the function\n",
    "X = pd.DataFrame(wvs_dum.loc[:, wvs_dum.columns != 'abortion'])\n",
    "y = pd.DataFrame(wvs_dum.abortion)\n",
    "lmodel = LogisticRegression()\n",
    "res = kfold2(10, lmodel, X, y)\n",
    "print('Mean accuracy of the result:', res[0])\n",
    "print('Mean fscore of the result:', res[1])\n",
    "print('Mean precision of the result:', res[2])\n",
    "print('Mean recall of the result:', res[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of the result: 1.0\n",
      "Mean fscore of the result: 1.0\n",
      "Mean precision of the result: 1.0\n",
      "Mean recall of the result: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Making a logistic regression model and sending it to the function\n",
    "X = pd.DataFrame(wvs2.loc[:, wvs2.columns != 'abortion'])\n",
    "y = pd.DataFrame(wvs2.abortion)\n",
    "lmodel = LogisticRegression()\n",
    "res = kfold2(10, lmodel, X, y)\n",
    "print('Mean accuracy of the result:', res[0])\n",
    "print('Mean fscore of the result:', res[1])\n",
    "print('Mean precision of the result:', res[2])\n",
    "print('Mean recall of the result:', res[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran the tests on the best model, i.e., Logistic Regression model which previously gave an accuracy of 1.0. The tests were run with and without countries.\n",
    "There was no difference in the accuracy with or without the countries. This was expected since accuracy was 1.0.\n",
    "To see a realistic difference in accuracy and understanding whether countries make a difference, I am running the same tests on an SVC classifier with poly kernel and degree=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am running the SVC model with poly kernel and degree 8 since it gave a comparable accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of the result: 0.9728\n",
      "Mean fscore of the result: 0.961885699625286\n",
      "Mean precision of the result: 0.9544931157831611\n",
      "Mean recall of the result: 0.9695475365318793\n"
     ]
    }
   ],
   "source": [
    "#With countries running on SVC with poly kernel and degree 8\n",
    "wvs_dum_sample = wvs_dum.sample(n=10000)\n",
    "X = pd.DataFrame(wvs_dum_sample.loc[:, wvs_dum_sample.columns != 'abortion'])\n",
    "y = pd.DataFrame(wvs_dum_sample.abortion)\n",
    "svclassifier = SVC(kernel='poly', degree=8)\n",
    "res = kfold2(10, svclassifier, X, y)\n",
    "print('Mean accuracy of the result:', res[0])\n",
    "print('Mean fscore of the result:', res[1])\n",
    "print('Mean precision of the result:', res[2])\n",
    "print('Mean recall of the result:', res[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of the result: 0.9639\n",
      "Mean fscore of the result: 0.9498898512718916\n",
      "Mean precision of the result: 0.95006228069222\n",
      "Mean recall of the result: 0.9497857203141739\n"
     ]
    }
   ],
   "source": [
    "#Without countries running on SVC with poly kernel and degree 8\n",
    "wvs2_sample = wvs2.sample(n=10000)\n",
    "X = pd.DataFrame(wvs2_sample.loc[:, wvs2_sample.columns != 'abortion'])\n",
    "y = pd.DataFrame(wvs2_sample.abortion)\n",
    "svclassifier = SVC(kernel='poly', degree=8)\n",
    "res = kfold2(10, svclassifier, X, y)\n",
    "print('Mean accuracy of the result:', res[0])\n",
    "print('Mean fscore of the result:', res[1])\n",
    "print('Mean precision of the result:', res[2])\n",
    "print('Mean recall of the result:', res[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after the data was tested with the SVC classifier, there was no significant difference with or without countries. \n",
    "\n",
    "The accuracy was 97% with country dummies and 96.3% without country dummies, therefore confirming that countries make very little impact.\n",
    "\n",
    "__Therefore, the country information does not help to noticeably improve the prediction.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DONE__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
