{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Explore and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data\n",
    "rotten = pd.read_csv('rotten-tomatoes.csv.bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.1 Take a look at a few lines of data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>link</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.timeout.com/film/reviews/87745/toy-...</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.time.com/time/magazine/article/0,91...</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The year's most inventive comedy.</td>\n",
       "      <td>2008-08-31 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>David Ansen</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.newsweek.com/id/104199</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.variety.com/review/VE1117941294.htm...</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://onfilm.chicagoreader.com/movies/capsule...</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh    imdb  \\\n",
       "0         Derek Adams  fresh  114709   \n",
       "1     Richard Corliss  fresh  114709   \n",
       "2         David Ansen  fresh  114709   \n",
       "3       Leonard Klady  fresh  114709   \n",
       "4  Jonathan Rosenbaum  fresh  114709   \n",
       "\n",
       "                                                link     publication  \\\n",
       "0  http://www.timeout.com/film/reviews/87745/toy-...        Time Out   \n",
       "1  http://www.time.com/time/magazine/article/0,91...   TIME Magazine   \n",
       "2                  http://www.newsweek.com/id/104199        Newsweek   \n",
       "3  http://www.variety.com/review/VE1117941294.htm...         Variety   \n",
       "4  http://onfilm.chicagoreader.com/movies/capsule...  Chicago Reader   \n",
       "\n",
       "                                               quote          review_date  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04 00:00:00   \n",
       "1                  The year's most inventive comedy.  2008-08-31 00:00:00   \n",
       "2  A winning animated feature that has something ...  2008-08-18 00:00:00   \n",
       "3  The film sports a provocative and appealing st...  2008-06-09 00:00:00   \n",
       "4  An entertaining computer-generated, hyperreali...  2008-03-10 00:00:00   \n",
       "\n",
       "   rtid      title  \n",
       "0  9559  Toy Story  \n",
       "1  9559  Toy Story  \n",
       "2  9559  Toy Story  \n",
       "3  9559  Toy Story  \n",
       "4  9559  Toy Story  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validating the data\n",
    "rotten.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.2 Print out all variable names.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['critic', 'fresh', 'imdb', 'link', 'publication', 'quote',\n",
       "       'review_date', 'rtid', 'title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing out the variable names\n",
    "rotten.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13442, 9)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the shape\n",
    "rotten.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.3 Create a summary table__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART A\n",
      "Number of missings in fresh: 0\n",
      "Number of missings in quote: 0 \n",
      "\n",
      "Part B\n",
      "All different values in fresh:\n",
      " fresh     8389\n",
      "rotten    5030\n",
      "none        23\n",
      "Name: fresh, dtype: int64 \n",
      "\n",
      "Part C\n",
      "percentage of fresh:\n",
      " 62.51583575527238\n",
      "percentage of rotten:\n",
      " 37.48416424472762 \n",
      "\n",
      "PART D\n",
      "Number of white spaces quotes are: 0\n",
      "Number of zero length quotes are: False \n",
      "\n",
      "Part E\n",
      "Number of minimum length quotes: 4\n",
      "Number of maximum length quotes: 256\n",
      "Number of average length quotes: 121.23128998660914 \n",
      "\n",
      "Part F\n",
      "Number of reviews are in data multiple times: 596\n"
     ]
    }
   ],
   "source": [
    "# Part a\n",
    "missing_fresh = rotten.fresh.isnull().sum()\n",
    "missing_quote = rotten.quote.isnull().sum()\n",
    "print(\"PART A\")\n",
    "print(\"Number of missings in fresh:\", missing_fresh)\n",
    "print(\"Number of missings in quote:\", missing_quote,\"\\n\")\n",
    "\n",
    "# Part b\n",
    "values = rotten.fresh.value_counts()\n",
    "print(\"Part B\")\n",
    "print(\"All different values in fresh:\\n\",values, \"\\n\")\n",
    "\n",
    "\n",
    "# Part c\n",
    "percentage_fresh = (8389 * 100)/(8389 + 5030)\n",
    "percentage_rotten = (5030/(8389+5030))*100\n",
    "\n",
    "print(\"Part C\")\n",
    "print(\"percentage of fresh:\\n\", percentage_fresh)\n",
    "print(\"percentage of rotten:\\n\", percentage_rotten, \"\\n\")\n",
    "\n",
    "\n",
    "# Part d\n",
    "# Check white spaces\n",
    "print(\"PART D\")\n",
    "print(\"Number of white spaces quotes are:\", sum(rotten.quote == '\\\\s+'))\n",
    "print(\"Number of zero length quotes are:\", len(rotten.quote) == 0, \"\\n\")\n",
    "\n",
    "# Part e\n",
    "# Find minimum-maximum-average length of quotes\n",
    "min_len = rotten.quote.str.len().min()\n",
    "max_len = rotten.quote.str.len().max()\n",
    "mean_len = rotten.quote.str.len().mean()\n",
    "\n",
    "print(\"Part E\")\n",
    "print(\"Number of minimum length quotes:\", min_len)\n",
    "print(\"Number of maximum length quotes:\", max_len)\n",
    "print(\"Number of average length quotes:\", mean_len, \"\\n\")\n",
    "\n",
    "# Part f\n",
    "print(\"Part F\")\n",
    "print(\"Number of reviews are in data multiple times:\", rotten.duplicated(subset=None, keep='first').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.4 Clean the data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a funtion to clean the data\n",
    "def clean(df):\n",
    "    df.drop_duplicates(subset = None, keep = 'first', inplace = True)\n",
    "    df.drop(df[df.fresh == 'none'].index, inplace=True)\n",
    "    df.drop(list(df['quote'].filter(regex = '\\\\s+')), axis = 1, inplace = True)\n",
    "    df.drop(df[df[\"quote\"].str.len() == 0].index, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning our data\n",
    "clean(rotten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12823, 9)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the final number of rows and columns\n",
    "rotten.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Naïve Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Split your data into training and validation and convert your data into bag of words__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10258, 9)\n",
      "(10258,)\n",
      "(2565, 9)\n"
     ]
    }
   ],
   "source": [
    "#Splitting data into training, validation and test\n",
    "target = rotten.fresh\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(rotten, target, test_size=0.2)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>link</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13092</td>\n",
       "      <td>Trevor Johnston</td>\n",
       "      <td>fresh</td>\n",
       "      <td>151568</td>\n",
       "      <td>http://www.timeout.com/film/reviews/79592/tops...</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>Leigh's cast are beyond compare, and the whole...</td>\n",
       "      <td>2006-02-09 00:00:00</td>\n",
       "      <td>13407</td>\n",
       "      <td>Topsy-Turvy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12421</td>\n",
       "      <td>Variety Staff</td>\n",
       "      <td>rotten</td>\n",
       "      <td>94012</td>\n",
       "      <td>http://www.variety.com/review/VE1117795083.htm...</td>\n",
       "      <td>Variety</td>\n",
       "      <td>Mel Brooks will do anything for a laugh. Unfor...</td>\n",
       "      <td>2009-03-26 00:00:00</td>\n",
       "      <td>10223</td>\n",
       "      <td>Spaceballs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rotten</td>\n",
       "      <td>88847</td>\n",
       "      <td>http://www.timeout.com/film/reviews/68404/the_...</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>An iconic movie of the '80s, with all the unap...</td>\n",
       "      <td>2006-06-24 00:00:00</td>\n",
       "      <td>14900</td>\n",
       "      <td>The Breakfast Club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>Hal Hinson</td>\n",
       "      <td>fresh</td>\n",
       "      <td>113161</td>\n",
       "      <td>http://www.washingtonpost.com/wp-srv/style/lon...</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>Irresistibly charming.</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>13680</td>\n",
       "      <td>Get Shorty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>James Berardinelli</td>\n",
       "      <td>rotten</td>\n",
       "      <td>110475</td>\n",
       "      <td>http://www.reelviews.net/php_review_template.p...</td>\n",
       "      <td>ReelViews</td>\n",
       "      <td>As a comedy, The Mask is genial, but its recyc...</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>11568</td>\n",
       "      <td>The Mask</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   critic   fresh    imdb  \\\n",
       "13092     Trevor Johnston   fresh  151568   \n",
       "12421       Variety Staff  rotten   94012   \n",
       "7984                  NaN  rotten   88847   \n",
       "148            Hal Hinson   fresh  113161   \n",
       "1725   James Berardinelli  rotten  110475   \n",
       "\n",
       "                                                    link      publication  \\\n",
       "13092  http://www.timeout.com/film/reviews/79592/tops...         Time Out   \n",
       "12421  http://www.variety.com/review/VE1117795083.htm...          Variety   \n",
       "7984   http://www.timeout.com/film/reviews/68404/the_...         Time Out   \n",
       "148    http://www.washingtonpost.com/wp-srv/style/lon...  Washington Post   \n",
       "1725   http://www.reelviews.net/php_review_template.p...        ReelViews   \n",
       "\n",
       "                                                   quote          review_date  \\\n",
       "13092  Leigh's cast are beyond compare, and the whole...  2006-02-09 00:00:00   \n",
       "12421  Mel Brooks will do anything for a laugh. Unfor...  2009-03-26 00:00:00   \n",
       "7984   An iconic movie of the '80s, with all the unap...  2006-06-24 00:00:00   \n",
       "148                               Irresistibly charming.  2000-01-01 00:00:00   \n",
       "1725   As a comedy, The Mask is genial, but its recyc...  2000-01-01 00:00:00   \n",
       "\n",
       "        rtid               title  \n",
       "13092  13407         Topsy-Turvy  \n",
       "12421  10223          Spaceballs  \n",
       "7984   14900  The Breakfast Club  \n",
       "148    13680          Get Shorty  \n",
       "1725   11568            The Mask  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13092     fresh\n",
       "12421    rotten\n",
       "7984     rotten\n",
       "148       fresh\n",
       "1725     rotten\n",
       "Name: fresh, dtype: object"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3769    rotten\n",
       "1279     fresh\n",
       "6066    rotten\n",
       "246      fresh\n",
       "7672     fresh\n",
       "Name: fresh, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>link</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8281</td>\n",
       "      <td>Roger Ebert</td>\n",
       "      <td>rotten</td>\n",
       "      <td>97523</td>\n",
       "      <td>http://www.rogerebert.com/reviews/honey-i-shru...</td>\n",
       "      <td>Chicago Sun-Times</td>\n",
       "      <td>The special effects are all there, nicely in p...</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>10611</td>\n",
       "      <td>Honey, I Shrunk the Kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2810</td>\n",
       "      <td>James Berardinelli</td>\n",
       "      <td>fresh</td>\n",
       "      <td>116282</td>\n",
       "      <td>http://www.reelviews.net/php_review_template.p...</td>\n",
       "      <td>ReelViews</td>\n",
       "      <td>It's easy to admire what the Coens are trying ...</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>104762093</td>\n",
       "      <td>Fargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12013</td>\n",
       "      <td>Variety Staff</td>\n",
       "      <td>fresh</td>\n",
       "      <td>57076</td>\n",
       "      <td>http://www.variety.com/review/VE1117791143.htm...</td>\n",
       "      <td>Variety</td>\n",
       "      <td>From Russia with Love is a preposterous, skill...</td>\n",
       "      <td>2008-04-15 00:00:00</td>\n",
       "      <td>10737</td>\n",
       "      <td>From Russia With Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1672</td>\n",
       "      <td>Mick LaSalle</td>\n",
       "      <td>rotten</td>\n",
       "      <td>110167</td>\n",
       "      <td>http://www.sfgate.com/cgi-bin/article.cgi?f=/c...</td>\n",
       "      <td>San Francisco Chronicle</td>\n",
       "      <td>The nastiness in the movie feels derived from ...</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>11028</td>\n",
       "      <td>It Could Happen to You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12767</td>\n",
       "      <td>Roger Ebert</td>\n",
       "      <td>fresh</td>\n",
       "      <td>101393</td>\n",
       "      <td>http://www.rogerebert.com/reviews/backdraft-1991</td>\n",
       "      <td>Chicago Sun-Times</td>\n",
       "      <td>[The scenes involving fire] are so good they m...</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>13033</td>\n",
       "      <td>Backdraft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   critic   fresh    imdb  \\\n",
       "8281          Roger Ebert  rotten   97523   \n",
       "2810   James Berardinelli   fresh  116282   \n",
       "12013       Variety Staff   fresh   57076   \n",
       "1672         Mick LaSalle  rotten  110167   \n",
       "12767         Roger Ebert   fresh  101393   \n",
       "\n",
       "                                                    link  \\\n",
       "8281   http://www.rogerebert.com/reviews/honey-i-shru...   \n",
       "2810   http://www.reelviews.net/php_review_template.p...   \n",
       "12013  http://www.variety.com/review/VE1117791143.htm...   \n",
       "1672   http://www.sfgate.com/cgi-bin/article.cgi?f=/c...   \n",
       "12767   http://www.rogerebert.com/reviews/backdraft-1991   \n",
       "\n",
       "                   publication  \\\n",
       "8281         Chicago Sun-Times   \n",
       "2810                 ReelViews   \n",
       "12013                  Variety   \n",
       "1672   San Francisco Chronicle   \n",
       "12767        Chicago Sun-Times   \n",
       "\n",
       "                                                   quote          review_date  \\\n",
       "8281   The special effects are all there, nicely in p...  2000-01-01 00:00:00   \n",
       "2810   It's easy to admire what the Coens are trying ...  2000-01-01 00:00:00   \n",
       "12013  From Russia with Love is a preposterous, skill...  2008-04-15 00:00:00   \n",
       "1672   The nastiness in the movie feels derived from ...  2000-01-01 00:00:00   \n",
       "12767  [The scenes involving fire] are so good they m...  2000-01-01 00:00:00   \n",
       "\n",
       "            rtid                     title  \n",
       "8281       10611  Honey, I Shrunk the Kids  \n",
       "2810   104762093                     Fargo  \n",
       "12013      10737     From Russia With Love  \n",
       "1672       11028    It Could Happen to You  \n",
       "12767      13033                 Backdraft  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validating the data\n",
    "X_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8281     rotten\n",
       "2810      fresh\n",
       "12013     fresh\n",
       "1672     rotten\n",
       "12767     fresh\n",
       "Name: fresh, dtype: object"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validating the test data\n",
    "y_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating bag of words for fresh and rotten\n",
    "\n",
    "f = X_train[X_train['fresh']=='fresh']\n",
    "r = X_train[X_train['fresh']=='rotten']\n",
    "\n",
    "#Fresh\n",
    "vectorizer1 = CountVectorizer(binary=True, stop_words='english')\n",
    "X = vectorizer1.fit_transform(f.quote.values)\n",
    "words = vectorizer1.get_feature_names()\n",
    "\n",
    "#Rotten\n",
    "vectorizer2 = CountVectorizer(binary=True, stop_words='english')\n",
    "X2 = vectorizer2.fit_transform(r.quote.values)\n",
    "words2 = vectorizer2.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.4 Compute the unconditional (log) probability that the tomato is fresh/rotten, log Pr(F), and log Pr(R).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4774397716872286\n",
      "-0.968557258351698\n"
     ]
    }
   ],
   "source": [
    "Pr_f = np.log(len(rotten[rotten['fresh'] == 'fresh']) / len(rotten['fresh'])) \n",
    "Pr_r = np.log(len(rotten[rotten['fresh'] == 'rotten']) / len(rotten['fresh']))\n",
    "print(Pr_f)\n",
    "print(Pr_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6375"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.5 For each word w, compute log Pr(w|F) and log Pr(w|R), the (log) probability that the word is present in a fresh/rotten review__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[matrix([[-8.06699219, -8.76013937, -6.68069783, ..., -8.76013937,\n",
      "         -8.76013937, -8.06699219]])]]\n",
      "[matrix([[-8.26436333, -7.57121615, -5.625306  , ..., -8.26436333,\n",
      "         -8.26436333, -8.26436333]])]\n"
     ]
    }
   ],
   "source": [
    "#Making log probability matrix for Fresh and Rotten vectors\n",
    "#Fresh\n",
    "mat1 = np.sum(X, axis=0)\n",
    "Pr_matrix1 = [[np.log(x/X.shape[0])] for x in mat1]\n",
    "\n",
    "#Rotten\n",
    "mat2 = np.sum(X2, axis=0)\n",
    "Pr_matrix2 = [np.log(x/X2.shape[0]) for x in mat2]\n",
    "\n",
    "\n",
    "print(Pr_matrix1)\n",
    "print(Pr_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.6 For both destination classes, F and R, compute the log-likelihood that the quote belongs to this class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making bag of words of validation set\n",
    "vec = CountVectorizer(binary=True, stop_words='english')\n",
    "X3 = vec.fit_transform(X_test.quote.values)\n",
    "words3 = vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14306\n",
      "11299\n",
      "8972\n"
     ]
    }
   ],
   "source": [
    "#Validating the data\n",
    "print(len(words))  # length of fresh\n",
    "print(len(words2)) # length of rotton\n",
    "print(len(words3)) # length of validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifying the validation data\n",
    "def classify(X3, words, Pr_matrix1, words2, Pr_matrix2, words3):\n",
    "    dict_quotes = {}\n",
    "    for i in range(X3.shape[0]):\n",
    "        sum_f = 0\n",
    "        sum_r = 0\n",
    "        for j in range(X3[i].shape[1]):\n",
    "            if(X3[i,j] == 1):\n",
    "                #Checking if the word in validation is present in Fresh set of words\n",
    "                if(words3[j] in words):\n",
    "                    sum_f += Pr_matrix1[0][0][0,words.index(words3[j])]\n",
    "\n",
    "                #Checking if the word in validation is present in Rotten set of words\n",
    "                if(words3[j] in words2):\n",
    "                    sum_r += Pr_matrix2[0][0][0,words2.index(words3[j])]\n",
    "\n",
    "        #Calculating likelihood of the quote\n",
    "        likelihood_f = Pr_f + sum_f\n",
    "        likelihood_r = Pr_r + sum_r\n",
    "        #Classifying as fresh or rotten\n",
    "        if(likelihood_f >= likelihood_r):\n",
    "            dict_quotes[i] = 'fresh'\n",
    "        else:\n",
    "            dict_quotes[i] = 'rotten'\n",
    "    return(dict_quotes)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2565"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_quotes = classify(X3, words, Pr_matrix1, words2, Pr_matrix2, words3)\n",
    "print(len(y_test))\n",
    "len(dict_quotes.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.7 Print the resulting confusion matrix and accuracy (feel free to use existing libraries).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[662, 918],\n",
       "       [403, 582]])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing confusion matrix of predicted values and actual values\n",
    "confusion_matrix(y_test, list(dict_quotes.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.484990253411306"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing the accuracy\n",
    "accuracy_score(y_test, list(dict_quotes.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.1 Extract from your conditional probability vectors log Pr(wjF) and log Pr(wjR) the probabilities that correspond to frequent words only__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a dictionary of frequent Fresh words and sorted them according to the log probabilities\n",
    "F_frequent = {}\n",
    "for i, key in enumerate(vectorizer1.vocabulary_):\n",
    "    if(vectorizer1.vocabulary_[key] > 30):\n",
    "        F_frequent[key] = Pr_matrix1[0][0][0,i]\n",
    "F_frequent = sorted(F_frequent.items(), key=lambda x: x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a dictionary of frequent Rotten words and sorted them according to the log probabilities\n",
    "R_frequent = {}\n",
    "for i, key in enumerate(vectorizer2.vocabulary_):\n",
    "    if(vectorizer2.vocabulary_[key] > 30):\n",
    "        R_frequent[key] = Pr_matrix2[0][0][0,i]\n",
    "R_frequent = sorted(R_frequent.items(), key=lambda x: x[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.2 Find 10 best words to predict F and 10 best words to predict R.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 best words for F:\n",
      "cast\n",
      "bighearted\n",
      "celebration\n",
      "entertainer\n",
      "lot\n",
      "stands\n",
      "cinema\n",
      "treasures\n",
      "charming\n",
      "babe\n",
      "\n",
      "10 best words for R:\n",
      "mel\n",
      "does\n",
      "spaceballs\n",
      "parody\n",
      "star\n",
      "wars\n",
      "adventures\n",
      "funny\n",
      "80s\n",
      "unappealing\n"
     ]
    }
   ],
   "source": [
    "print(\"10 best words for F:\")\n",
    "for i in range(10):\n",
    "    print(F_frequent[i][0])\n",
    "print(\"\")\n",
    "print(\"10 best words for R:\")\n",
    "for i in range(10):\n",
    "    print(R_frequent[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.3 Print out a few missclassified quotes. Can you understand why these are misclassified?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An empty triumph of overkill set design and weirdo casting.\n",
      "\n",
      "Pfieffer is absurdly miscast: Sly Stallone would make a more plausible Mr. Chips than the frail, squeaky actress does a nine-year veteran of the Marine Corps.\n",
      "\n",
      "The film is overcome by the rumbling workings of a creaky plot as the story grows more serious.\n",
      "\n",
      "The movie has everything a teenage boy could want... Everything, that is, but an interesting plot, decent dialogue and compelling acting.\n",
      "\n",
      "You'd think that decree No. 1 for a movie about rules would be to know exactly what kind of picture you're making and selling. Georgia Rule fails that basic test, and a whole lot of other ones besides.\n",
      "\n",
      "There isn't much of a story. The minimal plot exists exclusively to get the orangutan Dunston (played by \"Sam\") into as many odd, potentially-comic circumstances as possible.\n",
      "\n",
      "This startlingly uneventful compendium of thick-headed boy-talk and female tolerance squanders a fine cast on incredibly ordinary characters and situations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Some of the misclassified rotten quotes\n",
    "for i in range(200):\n",
    "    if(F_frequent[0][0] in rotten[rotten['fresh']=='rotten'].iloc[i].quote or\n",
    "       F_frequent[1][0] in rotten[rotten['fresh']=='rotten'].iloc[i].quote or\n",
    "       F_frequent[2][0] in rotten[rotten['fresh']=='rotten'].iloc[i].quote or\n",
    "       F_frequent[3][0] in rotten[rotten['fresh']=='rotten'].iloc[i].quote or\n",
    "       F_frequent[4][0] in rotten[rotten['fresh']=='rotten'].iloc[i].quote or\n",
    "       F_frequent[5][0] in rotten[rotten['fresh']=='rotten'].iloc[i].quote):\n",
    "        print(rotten[rotten['fresh']=='rotten'].iloc[i].quote)\n",
    "        print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As Lion King did before it, Toy Story revived the art of American children's animation, and ushered in a set of smart movies that entertained children and their parents. It's a landmark movie, and doesn't get old with frequent repetition.\n",
      "\n",
      "The result is a visionary roller-coaster ride of a movie.\n",
      "\n",
      "I can hardly imagine having more fun at the movies than I did at Toy Story, the miraculous new Disney feature that's the first full-length animated film to be produced entirely on computer.\n",
      "\n",
      "This is simply the best American crime movie -- and indeed, one of the finest movies, period -- in over a decade.\n",
      "\n",
      "Michael Mann and a superlative cast have taken a classic heist movie rife with familiar genre elements and turned it into a sleek, accomplished piece of work, meticulously controlled and completely involving.\n",
      "\n",
      "Boosters and touts use the term 'major movie' so often that it's more likely to generate yawns than excitement at this point. Back to basics. Heat is a major movie. With major stars. Doing major acting.\n",
      "\n",
      "Part romantic comedy, part Capra-corny political drama, this movie exudes so much sympathy, it sweats.\n",
      "\n",
      "What it finally adds up to is a huge mixed bag of waxworks and daring, a film that is furiously ambitious even when it goes flat, and startling even when it settles for eerie, movie-of-the-week mimicry.\n",
      "\n",
      "Nixon starts, like a horror movie, on a dark and stormy night, with the president prowling around a room of the White House like Dracula in his lair.\n",
      "\n",
      "[Stone] seems to be trying to enter a more passionate movie, where a neurotic gold digger could at least have a good time. By the end of Casino, for all its craftsmanly bravura, you may want to join her.\n",
      "\n",
      "Visually impressive, splendidly performed, thematically significant, this is a movie in full possession of every key cinematic asset except one -- a solid script.\n",
      "\n",
      "More viscerally charged than \"Speed\" and hipper than \"Die Hard With a Vengeance,\" the movie is a careening, screeching joyride that showers sparks like fireworks.\n",
      "\n",
      "Hollywood has been in love with mobsters since the beginning of movies. But the other side of the equation has seldom been considered. That is, until now.\n",
      "\n",
      "One of the pleasures of Get Shorty is watching the way the plot moves effortlessly from crime to the movies - not a long distance, since both industries are based on fear, greed, creativity and intimidation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Some of the misclassified fresh quotes\n",
    "for i in range(100):\n",
    "    if(R_frequent[0][0] in rotten[rotten['fresh']=='fresh'].iloc[i].quote or\n",
    "       R_frequent[1][0] in rotten[rotten['fresh']=='fresh'].iloc[i].quote or\n",
    "       R_frequent[2][0] in rotten[rotten['fresh']=='fresh'].iloc[i].quote or\n",
    "       R_frequent[3][0] in rotten[rotten['fresh']=='fresh'].iloc[i].quote or\n",
    "       R_frequent[4][0] in rotten[rotten['fresh']=='fresh'].iloc[i].quote or\n",
    "       R_frequent[5][0] in rotten[rotten['fresh']=='fresh'].iloc[i].quote or\n",
    "       R_frequent[6][0] in rotten[rotten['fresh']=='fresh'].iloc[i].quote or\n",
    "       R_frequent[7][0] in rotten[rotten['fresh']=='fresh'].iloc[i].quote or\n",
    "       R_frequent[8][0] in rotten[rotten['fresh']=='fresh'].iloc[i].quote):\n",
    "        print(rotten[rotten['fresh']=='fresh'].iloc[i].quote)\n",
    "        print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: NB with smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifying the validation data\n",
    "def classify_with_alpha(X3, words, Pr_matrix1, words2, Pr_matrix2, words3):\n",
    "    dict_quotes = {}\n",
    "    for i in range(X3.shape[0]):\n",
    "        sum_f = 0\n",
    "        sum_r = 0\n",
    "        for j in range(X3[i].shape[1]):\n",
    "            if(X3[i,j] == 1):\n",
    "                #Checking if the word in validation is present in Fresh set of words\n",
    "                if(words3[j] in words):\n",
    "                    sum_f += Pr_matrix1[0][0][0,words.index(words3[j])]\n",
    "                else:\n",
    "                    sum_f = 1\n",
    "\n",
    "                #Checking if the word in validation is present in Rotten set of words\n",
    "                if(words3[j] in words2):\n",
    "                    sum_r += Pr_matrix2[0][0][0,words2.index(words3[j])]\n",
    "                else:\n",
    "                    sum_r = 1\n",
    "\n",
    "        #Calculating likelihood of the quote\n",
    "        likelihood_f = Pr_f + sum_f\n",
    "        likelihood_r = Pr_r + sum_r\n",
    "        #Classifying as fresh or rotten\n",
    "        if(likelihood_f >= likelihood_r):\n",
    "            dict_quotes[i] = 'fresh'\n",
    "        else:\n",
    "            dict_quotes[i] = 'rotten'\n",
    "    return(dict_quotes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into training, validation and test\n",
    "target = rotten.fresh\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(rotten, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(X_train, y_train,X_test, alpha):\n",
    "    f = X_train[X_train['fresh']=='fresh']\n",
    "    r = X_train[X_train['fresh']=='rotten']\n",
    "\n",
    "    #Fresh\n",
    "    vectorizer1 = CountVectorizer(binary=True, stop_words='english')\n",
    "    X = vectorizer1.fit_transform(f.quote.values)\n",
    "    words = vectorizer1.get_feature_names()\n",
    "\n",
    "    #Rotten\n",
    "    vectorizer2 = CountVectorizer(binary=True, stop_words='english')\n",
    "    X2 = vectorizer2.fit_transform(r.quote.values)\n",
    "    words2 = vectorizer2.get_feature_names()\n",
    "    Pr_f = np.log((len(rotten[rotten['fresh'] == 'fresh']) + alpha) / (len(rotten['fresh']) + alpha))\n",
    "    Pr_r = np.log((len(rotten[rotten['fresh'] == 'rotten']) + alpha) / (len(rotten['fresh']) + alpha))\n",
    "    mat1 = np.sum(X, axis=0)\n",
    "    Pr_matrix1 = [[np.log((x + alpha)/(X.shape[0]+ alpha))] for x in mat1]\n",
    "\n",
    "    #Rotten\n",
    "    mat2 = np.sum(X2, axis=0)\n",
    "    Pr_matrix2 = [np.log((x + alpha)/(X2.shape[0]+ alpha)) for x in mat2]\n",
    "\n",
    "    #Making bag of words of validation set\n",
    "    vec = CountVectorizer(binary=True, stop_words='english')\n",
    "    X3 = vec.fit_transform(X_test.quote.values)\n",
    "    words3 = vec.get_feature_names()\n",
    "\n",
    "    dict_quotes = classify_with_alpha(X3, words, Pr_matrix1, words2, Pr_matrix2, words3)\n",
    "    \n",
    "    return(dict_quotes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### Cross-Validate the accuracy on different values of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing kfold cross validation\n",
    "kfold = KFold(n_splits=5, random_state=100, shuffle=False)\n",
    "\n",
    "def cross_validate(X, alpha):\n",
    "    accu = 0\n",
    "    for train_index, test_index  in kf.split(X):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train1, y_test1 = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        \n",
    "        dict_quotes = fit_model(X_train, y_train1,X_test, alpha)\n",
    "        accu = accu + accuracy_score(y_test1, list(dict_quotes.values()))\n",
    "        \n",
    "    return accu   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 2052  2053  2054 ... 10255 10256 10257] TEST: [   0    1    2 ... 2049 2050 2051]\n",
      "TRAIN: [    0     1     2 ... 10255 10256 10257] TEST: [2052 2053 2054 ... 4101 4102 4103]\n",
      "TRAIN: [    0     1     2 ... 10255 10256 10257] TEST: [4104 4105 4106 ... 6153 6154 6155]\n",
      "TRAIN: [    0     1     2 ... 10255 10256 10257] TEST: [6156 6157 6158 ... 8204 8205 8206]\n",
      "TRAIN: [   0    1    2 ... 8204 8205 8206] TEST: [ 8207  8208  8209 ... 10255 10256 10257]\n",
      "TRAIN: [ 2052  2053  2054 ... 10255 10256 10257] TEST: [   0    1    2 ... 2049 2050 2051]\n",
      "TRAIN: [    0     1     2 ... 10255 10256 10257] TEST: [2052 2053 2054 ... 4101 4102 4103]\n",
      "TRAIN: [    0     1     2 ... 10255 10256 10257] TEST: [4104 4105 4106 ... 6153 6154 6155]\n",
      "TRAIN: [    0     1     2 ... 10255 10256 10257] TEST: [6156 6157 6158 ... 8204 8205 8206]\n",
      "TRAIN: [   0    1    2 ... 8204 8205 8206] TEST: [ 8207  8208  8209 ... 10255 10256 10257]\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "alpha_values = [0.3,0.5]\n",
    "for alpha in alpha_values:\n",
    "    accuracy.append(cross_validate(X_train, alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49892768515904856, 0.49931754870680684]\n",
      "The mean accuracy is highest for following value of alpha: 0.5\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = [a/5 for a in accuracy]\n",
    "print(mean_accuracy)\n",
    "print(\"The mean accuracy is highest for following value of alpha:\",0.5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After cross-validation, we found the best accuracy of 49.93 % when alpha is 0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
